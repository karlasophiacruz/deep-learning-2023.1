{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa0352fe",
   "metadata": {},
   "source": [
    "# Redes Neurais - AP1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4d4a40",
   "metadata": {},
   "source": [
    "##### 1. Cite a principal limitação do Perceptron e como ela ficou popularmente conhecida. Qual a estratégia foi proposta para contornar tal limitação?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baecdd6f",
   "metadata": {},
   "source": [
    "**Problema da linearidade**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a72565f",
   "metadata": {},
   "source": [
    "A principal limitação do Perceptron é a incapacidade de lidar com problemas que não são linearmente separáveis, ou seja, se os dados não podem ser divididos em duas classes distintas por um única linha reta (ou hiperplano), o Perceptron não será capaz de aprender a separá-los corretamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ead752",
   "metadata": {},
   "source": [
    "A estratégia proposta para contornar essa limitação foi a de **Perceptrons Multicamadas** ou **(MLPs)**, que consistem de múltiplas camadas de neurônios interconectados. A intrudução de camadas intermediárias (camadas ocultas) com funções de ativação não lineares permitiu que essas redes fossem capazes de aprender a representar relações complexas entre os dados, e assim, superar o problema da separabilidade linear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d28fe20",
   "metadata": {},
   "source": [
    "A **propagação para trás (backpropagation)** é um algoritmo frequentemente usado para treinar redes neurais multicamadas, ajustando os pesos das conexões entre os neurônios para minimizar o erro entre as saídas esperadas e as saídas reais da rede."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fe9f01",
   "metadata": {},
   "source": [
    "##### 2. Qual a função de ativação do perceptron?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28934b77",
   "metadata": {},
   "source": [
    "A função de ativação do Perceptron original é geralmente uma **função degrau (step function)** binária. Essa função atribui uma saída de 0 ou 1, dependendo se o resultado ponderado das entradas do Perceptron é maior ou igual a um determinado limiar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7b8ee9",
   "metadata": {},
   "source": [
    "$$f(x) = 1, \\ x \\geq 0$$\n",
    "$$f(x) = 0, \\ x < 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea55a0b2",
   "metadata": {},
   "source": [
    "Também pode ser definida como"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893dc9d8",
   "metadata": {},
   "source": [
    "$$f(x) = 1, \\ \\sum{((w * x) + bias)} \\geq limiar $$\n",
    "$$f(x) = 0, \\ c.c.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78611065",
   "metadata": {},
   "source": [
    "##### 3. Qual a função de ativação utilizada na regressão logística? Qual a expressão da derivada correspondente?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123c391c",
   "metadata": {},
   "source": [
    "\n",
    "A função de ativação utilizada na regressão logística é a função sigmoid, também conhecida como função logística. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9552473",
   "metadata": {},
   "source": [
    "$$ s(z) = \\frac{1}{1 + e^{-z}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6155f5a1",
   "metadata": {},
   "source": [
    "Nessa equação, \"$z$\" representa o resultado ponderado das entradas e dos pesos da regressão logística."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200a2f44",
   "metadata": {},
   "source": [
    "$$ s'(z) = s(z) * (1 - s(z))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498292f5",
   "metadata": {},
   "source": [
    "Essa derivada é usada no algoritmo de otimização chamado **descida de gradiente (gradient descent)** para ajustar os pesos da regressão logística durante o processo de treinamento. A função sigmoid é diferenciável em todos os pontos, o que a torna adequada para calcular gradientes e atualizar os pesos de maneira iterativa para minimizar a função de perda durante o treinamento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abd9996",
   "metadata": {},
   "source": [
    "##### 4. Explique com suas palavras quais são as etapas principais do processo de treinamento de um neurônio. Explique cada etapa de forma sucinta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bee4542",
   "metadata": {},
   "source": [
    "O processo de treinameto de um neurônio, como o perceptron, envolve várias etapas que permitem ao neurônio aprender a fazer previsões ou classificações com base nos dados de entrada. As etapas principais são:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58eafbc8",
   "metadata": {},
   "source": [
    "**1. Inicialização dos PESOS e VIÉS**\n",
    "> os pesos e o viés do neurônio são inicializados com valores aleatórios ou \n",
    "> pequenos valores próximos de zero.\n",
    "> \n",
    "> Os pesos determinam a inflência de cada entrada no cálculo da saída.\n",
    "> \n",
    "> O viés ajusta o ponto de ativação do neurônio.\n",
    "\n",
    "**2. Cálculo da SAÍDA**\n",
    "> a saída do neurônio é calculada a partir da soma ponderada das entradas com\n",
    "> os pesos correspondentes e o viés.\n",
    ">\n",
    "> O resultado da soma é passado para a função de ativação, que determina se o neurônio será ativado ou não.\n",
    "\n",
    "**3. Cálculo do ERRO**\n",
    "> o erro é calculado a partir da diferença entre o valor esperado e o valor obtido na saída do neurônio.\n",
    "> \n",
    "> isso resulta em uma medida de quão bem o neurônio está realizando a tarefa.\n",
    "\n",
    "**4. Atualização dos PESOS e VIÉS (PARÂMETROS)**\n",
    "> o perceptron, backpropagation, ou descida do gradiente ajusta os pesos e o viés do neurônio proporcionalmente ao erro calculado. \n",
    ">\n",
    "> é feito usando informações sobre a direção em que o erro está dimuindo para mnimizá-lo.\n",
    "\n",
    "**5. Repetição (ITERAÇÃO)**\n",
    "> os passos 2, 3 e 4 são repetidos até que o erro seja suficientemente pequeno ou um número máximo de iterações seja alcançado, de modo a melhorar seu desempenho em previsões ou classificações.\n",
    "\n",
    "**6. Convergência (PARADA)**\n",
    "> o treinamento é interrompido quando o erro é suficientemente pequeno ou um número máximo de iterações é alcançado.\n",
    ">\n",
    "> o neurônio é considerado treinado quando seus pesos e viés alcançam valores que produzem resultados satisfatório em termos de desempenho.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853368c5",
   "metadata": {},
   "source": [
    "Em resumo, o processo de treinamento de um neurônio envolve ajustar os pesos e o viés para que o neurônio possa aprender a representar corretamente os padrões nos dados de entrada e, assim, realizar a tarefa desejada com precisão."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c1c515",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5fd2de0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee89a84f",
   "metadata": {},
   "source": [
    "## Parte 2 -- Prática/Desenvolvimento de código.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f31759b1",
   "metadata": {},
   "source": [
    "5. Utilize uma rede neural a partir de uma interpretação de regressão logística para classificar a base de dados `iris`.\n",
    "6. Utilize regressão para predizer preços de residências utilizando a base de dados `boston_housing`, disponível no `Keras`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba1770d5",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl] *",
   "language": "python",
   "name": "conda-env-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
